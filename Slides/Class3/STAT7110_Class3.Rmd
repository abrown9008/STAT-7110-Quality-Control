---
title: "S & S-Squared Control Charts and a Deeper Dive into Process Capability"
author: "Dr. Austin Brown"
institute: "Kennesaw State University"
output: beamer_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Table of Contents

1. $\bar{X}$ and $s$ Charts
2. $\bar{X}$ and $s^2$ Charts
3. Additional Process Capability Indices and Techniques

## Introduction

- In last week's class, we learned how to estimate a univariate process's mean and standard deviation using the sample mean,($\hat{\mu} = \bar{X}$), and mean of the sample ranges scaled by $d_2$, ($\hat{\sigma} = \bar{R}/d_2$).

\vskip 0.10 in

- When we're estimating parameters in general, one of the properties we like to have in an estimator is that it is consistent, which generally means that as our sample size increases, the estimator gets closer to the true value of the parameter.

\vskip 0.10 in

- The sample range does not have this property. While your text says this occurs when $n$ is roughly 10 or greater, more recent studies suggest is occurs in samples as small as $n=2$.

## Introduction

- Obviously, it is in our best interest to have a good estimate of the process's standard deviation as this estimate is relied upon for both Phase II monitoring as well as capability analysis.

\vskip 0.10 in

- In this class, we will learn about how to use the sample variance, $s^2$, and sample standard deviation, $s$, when working with Shewhart $\bar{X}$-charts in addition to learning about additional useful techniques in process capability.

## The Shewhart $\bar{X}$ and $s$ Charts

- As your text states, when we have a relatively large sample or when our sample size is variable from trial to trial, it is advised to use the $\bar{X}$ and $s$ Charts instead of the $\bar{X}$ and $R$ charts. 

\vskip 0.10 in

- The general principles behind the former chart are similar to what the charts we'll be discussing today.

\vskip 0.10 in

- So if we want to use $s$ instead of $\bar{R}/d_2$ as our estimate for process standard deviation, how does this change our control limits?

## The Shewhart $\bar{X}$ and $s$ Charts

- First, you probably know this already but just as a reminder, we will be using the unbiased estimator $s^2$ to estimate process variance:

$$ s^2 = \frac{1}{n-1}\sum_{i=1}^{n}(x_i - \bar{x})^2 $$
- As it is customary to use the square root of this estimator to estimate process standard deviation, let

$$ s = \sqrt{s^2} $$

## The Shewhart $\bar{X}$ and $s$ Charts

- However, $s$ is a biased estimator of $\sigma$. In fact, it can be shown:

$$ E[s] = \sigma\sqrt{\frac{2}{n-1}}\frac{\Gamma(n/2)}{\Gamma((n-1)/2)} $$

- We typically refer to the scaling constant as:

$$ c_4 = \sqrt{\frac{2}{n-1}}\frac{\Gamma(n/2)}{\Gamma((n-1)/2)} $$

## The Shewhart $\bar{X}$ and $s$ Charts

- If we know $\sigma$, the $s$ chart's control limits are:

$$ UCL = c_4\sigma + 3\sigma\sqrt{1-c_4^2} $$
$$ LCL = c_4\sigma - 3\sigma\sqrt{1-c_4^2} $$


## The Shewhart $\bar{X}$ and $s$ Charts

- If we're using 3 $\sigma$ limits, then we can slightly modify the control limits to:

$$ UCL = B_6\sigma $$
$$ LCL = B_5\sigma $$

- Remember, all of these constants can be found online at <https://web.mit.edu/2.810/www/files/readings/ControlChartConstantsAndFormulae.pdf>. 

## The Shewhart $\bar{X}$ and $s$ Charts

- Typically, we do not know what $\sigma$ is so we have to estimate it in Phase I. 

\vskip 0.10 in

- Like with the $R$-chart, in Phase I, we get an unbiased estimate of $\sigma$ by taking $m$ samples of size $n$. Then our estimator is:

$$ \hat{\sigma} = \frac{\bar{s}}{c_4} = \frac{1}{mc_4}\sum_{i=1}^{m}s_i $$

## The Shewhart $\bar{X}$ and $s$ Charts

- Now, the control limits for the $s$-chart from before are altered slightly and become:

$$ UCL = \bar{s} + \frac{3\bar{s}}{c_4}\sqrt{1-c_4^2} $$
$$ LCL = \bar{s} - \frac{3\bar{s}}{c_4}\sqrt{1-c_4^2} $$

- Again, if we are using 3 $\sigma$ limits, we can redefine the control limits for the $s$-chart as:

$$ UCL = B_4\bar{s} $$
$$ LCL = B_3\bar{s} $$


## The Shewhart $\bar{X}$ and $s$ Charts

- Now that we have set up the control limits for the $s$-chart, we can modify our control limits for the $\bar{X}$-chart:

$$ UCL = \bar{\bar{x}} + \frac{3\bar{s}}{c_4\sqrt{n}} $$
$$ LCL = \bar{\bar{x}} - \frac{3\bar{s}}{c_4\sqrt{n}} $$

- If we are using 3 $\sigma$ control limits, we can rewrite the control limits as:

$$ UCL = \bar{\bar{x}} + A_3\bar{s} $$
$$ LCL = \bar{\bar{x}} - A_3\bar{s} $$


## The Shewhart $\bar{X}$ and $s$ Charts

- Let's go through an example. Let's say the process we're monitoring is the manufacturing of piston rings for car engines. The quality characteristic we're measuring is the inside diameter of the rings, in millimeters. 

\vskip 0.10 in

- I have uploaded $m=25$ samples of size $n=5$ to D2L. Let's calculate our control limits in R for Phase I analysis. Then, once we've established statistical control, let's use the Phase I limits and center values in Phase II using the Phase II rings data.

## The Shewhart $\bar{X}$ an $s$ Charts

- As mentioned at the onset, one of the reasons to use the $s$ chart instead of the $R$ chart is in situations where our sample size varies from sample to sample. 

\vskip 0.10 in

- Such a situation is likely to occur in a situation like our coffee shop customer satisfaction surveys. 

\vskip 0.10 in

- Here, we would have to modify our estimation of both $\mu$ and $\sigma$


## The Shewhart $\bar{X}$ and $s$ Charts

$$ \hat{\mu} = \bar{\bar{x}} = \frac{\sum_{i=1}^{m}n_i\bar{x}_i}{\sum_{i=1}^{m}n_i} $$

$$ \bar{s} = \Bigg[\frac{\sum_{i=1}^{m}(n_i-1)s_i^2}{\sum_{i=1}^{m}n_i - m}\Bigg]^{1/2} $$

- Now, to calculate control limits, we have to be careful because $c_4$, $D_3$, $D_4$ and $A_3$ are all dependent on sample size and will thus change with a change in the sample size. 


## The Shewhart $\bar{X}$ and $s$ Charts

- If the sample size doesn't vary wildly and there are lots of samples with the same number of observations, your text suggests taking the average sample standard deviation from those samples with the mode sample size, and using the standard estimate:

$$ \hat{\sigma} = \frac{\bar{s}}{c_4} $$

- However, in my opinion, the criteria for using this method are nebulous, and also omit data points, which could decrease the consistency of the estimator. 

## The $s^2$ Chart

- While the $s$ chart is used quite a lot in industry, there is one reason people may potentially avoid it. 

\vskip 0.10 in

- When our observations come from a normal distribution, and the size of our samples are small ($n < 10$), the sampling distribution of $s$ is asymmetric, and thus, using 3 $\sigma$ limits yields a true $\alpha$ value that is different from the $0.0027$ we expect with such limits. 

\vskip 0.10 in

- Because of this limitation, some may be inclined to use a control chart which is built on the exact statistical properties of the plotting statistic, which is where the $s^2$ chart comes into play.

## The $s^2$ Chart

- We know from prior statistics courses that (again, if the underlying observations come from a normal distribution):

$$ \frac{(n-1)s^2}{\sigma^2} \sim \chi^2(n-1) $$

- Using confidence interval principles, we can see that if the process is in-control that we would expect:

$$ P\bigg[\chi^2_{\alpha/2,n-1} < \frac{(n-1)s^2}{\sigma^2} < \chi^2_{1-\alpha/2,n-1}\bigg] = 1-\alpha $$

## The s^2 Chart 

- Rearranging things a bit:

$$ P\Bigg[\frac{\sigma^2\chi^2_{\alpha/2,n-1}}{n-1} < s^2 < \frac{\sigma^2\chi^2_{1-\alpha/2,n-1}}{n-1}\Bigg] = 1 - \alpha $$

- If we know $\sigma^2$, we can use that, but if we don't, the text suggests collecting $m$ Phase I samples of size $n$, calculating the sample variance for each sample and then using the mean of those variances ($\bar{s}^2$) as your estimator for $\sigma^2$.

## The $s^2$ Chart

- Unfortunately, there is not a built-in function (that I can find) in R that can automatically generate this control chart for you. 

\vskip 0.10 in

- However, you can create the chart manually. I have included R code to create the $s^2$ chart using the non-missing piston rings data.

## Control Charts for Individual Measurements

- In practice, there are lots of instances where your sample size may be $n=1$. 

\vskip 0.10 in

- For example, in service industries, we may rather analyze customer satisfaction or time-to-service at the individual level rather than in aggregate. 

\vskip 0.10 in

- We may also encounter this situation in fast-paced manufacturing environments where observations are automatically performed for each unit produced. 

## Control Charts for Individual Measurements

- In these situations where the sample size is $n=1$ \textbf{\underline{and}} the magnitude of a shift away from target is relatively large (i.e., $>2\sigma$), then your text suggests utilization of the Control Chart for Individual Measurements along with a Moving Range Chart. 

\vskip 0.10 in

- The plotting statistic for the CCIM is obviously just a single observed value. For the MR Chart, we define the plotting statistic as:

$$ MR_i = |x_i - x_{i-1}| $$

## Control Charts for Individual Measurements

- The control limits for the CCIM are:

$$UCL = \bar{x} + \frac{3\bar{MR}}{d_2} $$
$$LCL = \bar{x} - \frac{3\bar{MR}}{d_2} $$


- And here, the sample size we use for $d_2$ is $n=2$.

## Control Charts for Individual Measurements

- The control limits for the MR Chart are:

$$UCL = D_4\bar{MR}$$
$$LCL = D_3\bar{MR}$$

- Let's look at an example of how to generate these charts in R. In D2L, we're going to use the Mortgage Loan Processing Costs dataset. 


## Control Charts for Individual Measurements

- There are a couple of things to be mindful of when interpreting the CCIM and MR Charts, with specific respect to the latter.

\vskip 0.10 in

- As you probably noted, the MR at a current time point is a function of the MR at the previous time point, thusly implying autocorrelation is inherently present.

\vskip 0.10 in

- Resultingly, patterns are likely to show up on the chart that really aren't indicative of a change in process variability at all. In fact, some argue that the MR Chart isn't really all that useful because of this. 

## Control Charts for Individual Measurements

- Additionally, the MR Chart, like the R-chart isn't really all that efficient at measuring changes in process variability because it's really measuring changes in mean level.

\vskip 0.10 in

- With regards to the CCIM, it can be shown that:

\begin{table}[h]
  \centering
  \begin{tabular}{|c|c|c|}
  \hline
  \text{Size of Shift} & $\beta$ & $ARL_1$ \\
  \hline
  $1\sigma$ & 0.9772 & 43.96 \\
  $2\sigma$ & 0.8413 & 6.30 \\
  $3\sigma$ & 0.5000 & 2.00 \\
  \hline
  \end{tabular}
\end{table}

- This means CCIM is highly inefficient at detecting small shifts.

## Control Charts for Individual Measuremnts

- Moreover, CCIM is highly sensitive to non-normality (we don't have the benefit of the CLT with individual observations). 

\vskip 0.10 in

- In fact, the IC-ARL can be deteriorated by over half in the presence of heavy tailed data, such as that which comes from a $t$ distribution with few degrees of freedom. 

## Deeper Dive into Process Capability

- Remember from last week, process capability analysis is a set of procedures/statistical tools that we can use in order to measure process variability, and compare that to technical process specifications.

\vskip 0.10 in

- This is commonly talked about in terms of manufacturing processes, but as we have seen, it can be applied to non-manufacturing processes, too.

\vskip 0.10 in

- We have seen how we can use the $C_p$ index to measure process capability as well as how we can use the humble histogram to compare process variability to technical specifications.

## Deeper Dive into Process Capability: $C_{pk}$ and $C_{pm}$

- However, there are other indices that can be used to measure process capability.

\vskip 0.10 in

- For example, with the $C_p$ index, we are assuming that the process is centered on the target value.

\vskip 0.10 in

- That is, we are assuming that the process mean lies directly between the upper and lower specification limits.
    - This also implies that we are assuming that $\bar\bar{{x}}$ is equal to the target value set by specification.

\vskip 0.10 in

- This might not always be reasonable!

## Deeper Dive into Process Capability: $C_{pk}$ and $C_{pm}$

- Let's consider the example from last week. Suppose we are manufacturing USB sticks. The target value for their width is 0.5 mm, the USL is 0.55 mm and the LSL is 0.45 mm.

\vskip 0.10 in

- The process is considered "centered" if our estimate for $\bar{\bar{x}} \approx 0.5$ mm. If not, then the process is considered "off-center".

\vskip 0.10 in

- Let's take a look at how this might appear in a histogram.

## Deeper Dive into Process Capability: $C_{pk}$ and $C_{pm}$

```{r,echo=F}
## Example of a Centered Process ##
set.seed(123)
n <- 1000
x <- rnorm(n,mean=0.5,sd=0.02)
library(ggplot2)
ggplot(data.frame(x=x),aes(x=x)) + 
  geom_histogram(bins=nclass.Sturges(x),fill="white",color="black") + 
  geom_vline(xintercept=0.5,color="red",linetype="dashed") +
  geom_vline(xintercept=0.45,color='red',linetype='dashed') +
  geom_vline(xintercept=0.55,color='red',linetype='dashed') +
  labs(title="A Centered Process") +
  theme_minimal() +
  theme(plot.title=element_text(hjust=0.5))
```

## Deeper Dive into Process Capability: $C_{pk}$ and $C_{pm}$

```{r,echo=F}
## Example of an Off-Centered Process ##
n <- 1000
x <- rnorm(n,mean=0.53,sd=0.02)
ggplot(data.frame(x=x),aes(x=x)) + 
  geom_histogram(bins=nclass.Sturges(x),fill="white",color="black") + 
  geom_vline(xintercept=0.5,color="red",linetype="dashed") +
  geom_vline(xintercept=0.45,color='red',linetype='dashed') +
  geom_vline(xintercept=0.55,color='red',linetype='dashed') +
  labs(title="An Off-Centered Process") +
  theme_minimal() +
  theme(plot.title=element_text(hjust=0.5))
```

## Deeper Dive into Process Capability: $C_{pk}$ and $C_{pm}$

- As we can see, that if we incorrectly assume that the process is centered, we may greatly overestimating the process's capability.

\vskip 0.10 in

- How do we address this problem? We have a few different ways but one of which is to use the $C_{pk}$ index, first introduced by KSU's own Dr. Victor Kane.

## Deeper Dive into Process Capability: $C_{pk}$ and $C_{pm}$

- The $C_{pk}$ index is defined as:

$$ \hat{C}_{pk} = \text{min}\Bigg[\frac{USL - \bar{\bar{x}}}{3s},\frac{\bar{\bar{x}} - LSL}{3s}\Bigg] $$

## Deeper Dive into Process Capability: $C_{pk}$ and $C_{pm}$

- This measure is interpreted in a manner very similar to the $C_p$ index.
    - That is, if $\hat{C}_{pk} > 1$, then the process is considered to be capable.
    - If $\hat{C}_{pk} < 1$, then the process is considered to be incapable.
    
\vskip 0.10 in

- The $C_{pk}$ index is a measure of how well the process is centered on the target value by focusing on which of the two specification limits is closer to the process mean.

## Deeper Dive into Process Capability: $C_{pk}$ and $C_{pm}$

- Let's look at a new example. Suppose we are manufacturing a new type of battery. The target value for the battery's voltage is 1.5 volts, the USL is 1.6 volts and the LSL is 1.4 volts.

\vskip 0.10 in

- The Phase I data for the battery's voltage is in the file "Battery Voltage Phase I Data.xlsx". Let's first determine if the process is in statistical control. Then, let's calculate the $\hat{C}_p$, the $FNC$, and the $\hat{C}_{pk}$ indices for the battery's voltage.

## Deeper Dive into Process Capability: $C_{pk}$ and $C_{pm}$

- So far, we have seen how we can use the $C_p$ and $C_{pk}$ indices to measure process capability. 

\vskip 0.10 in

- However, there is another index that we can use to measure process capability, the $C_{pm}$ index.

\vskip 0.10 in

- With $C_p$ and $C_{pk}$, we account for the process's variability through our estimate $\hat{\sigma} = \bar{s}/c_4$. 

\vskip 0.10 in

- However, we don't account for the process's centering, which we can quantify by $\bar{\bar{x}} - \text{Target}$.
    - Note, sometimes we just use $T$ to mean "Target". 
    
## Deeper Dive into Process Capability: $C_{pk}$ and $C_{pm}$

- This is where the $C_{pm}$ index comes in.

\vskip 0.10 in

- The $C_{pm}$ index is defined as:

$$ \hat{C}_{pm} = \frac{USL - LSL}{6\sqrt{\hat{\sigma}^2 + (\bar{\bar{x}} - T)^2}} $$

- Here, we can use $s^2 = \hat{\sigma}^2$.

## Deeper Dive into Process Capability: $C_{pk}$ and $C_{pm}$

- With this measure, we are penalizing the process for being off-center in our estimate of the process's capability.

\vskip 0.10 in

- As the process becomes more off-centered, which means that $\bar{\bar{x}}$ is further from the target value, $T$, the $C_{pm}$ index will decrease and give us an indication of poorer process capability compared to $C_p$ and $C_{pk}$.

## Deeper Dive into Process Capability: $C_{pk}$ and $C_{pm}$

- In the \texttt{process.capability} function in R, $C_{pm}$ is output by default. We can see in the Battery Voltage example that $C_{pm} < C_{pk} < C_p$.

\vskip 0.10 in

- And in this case, since $C_{pm} < 1$, we would say that the process is incapable.

\vskip 0.10 in

- Note, there is a metric called $C_{pmk}$ which is calculated in a manner similar to $C_{pk}$ but with $C_{pm}$ in place of $C_p$.

## Conclusion

- In this class, we learned about how to use the sample variance, $s^2$, and sample standard deviation, $s$, when working with Shewhart $\bar{X}$-charts in addition to learning about additional useful techniques in process capability.

\vskip 0.10 in

- We also learned about the $C_{pk}$ and $C_{pm}$ indices and how they can be used to measure process capability.

\vskip 0.10 in

- In the next class, we will learn about how to use the CUSUM and EWMA control charts as alternatives to the Shewhart $\bar{X}$ chart for monitoring a univariate continuous process.
